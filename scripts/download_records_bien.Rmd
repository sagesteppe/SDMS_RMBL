---
title: "Download records from bien"
author: "steppe"
date: "3/31/2022"
output: pdf_document
---

```{r load libraries, results='hide', message=F, warning=F}
library(tidyverse) # data tidying
library(sf) # spatial data compliant with tidyverse
library(here)
library(BIEN)
set.seed(12)
```

```{r import coords and prepare for upload to database}
poly_coords <- st_read(
  paste0(here(), '/data/processed/BIEN_polygons', Sys.Date(), '.shp'), 
  quiet = T) 

polygons <- split(poly_coords, ~Polygon) |>
  lapply(as, 'Spatial')

rm(poly_coords)
```

```{r prepare function to download values from server, eval = F}

BIEN_downloader <- function(x){
  
  occurrences <- BIEN_occurrence_spatialpolygons(x)
  occurrences <- st_as_sf(occurrences)
  occs2write  <- bind_cols(occurrences, x$Radius) 

  st_write(occs2write, 
           paste0(here(), '/data/raw/BIEN_rcrds', x$Polygon, "_", Sys.Date(), '.shp')
  )
  
  writeLines(
    paste0('The ', x$Polygon, 'polygon has completed downloading as of: ', Sys.time())
  )
}

lapply(polygons, BIEN_downloader)

```

# CHANGE IN APPROACH - DO NOT USE MULTIPLE DOWNLOADS FROM SERVER.  USE LARGEST APPROACH 100 KM RADIUS AND DOWNLOAD ALL GEOREFERENCED RECORDS. THEN USE ST_DISTANCE BETWEEN THE COORDINATES CENTROID. GROUP BY SPECIES AND SELECT FOR THE SHORTEST DISTANCE TO CENTROID. - THIS PROVIDES CONTINUOUS PREDICTOR (DISTANCE) TO A LOGISTIC REGRESSION. 

# AFTER COLLECTION DISTANCES RUN %IN% TO APPEND 1,0 PRESENCE/ABSENCE TO RMBL FIELD SITE.

split data set
```{r split data set, echo = F}
index <- caret::createDataPartition(testing_data$occurrence, p = .70, list = FALSE)
train <- testing_data[ index, ]
test  <- testing_data[-index, ]
rm(index)
```


```{r fit model, echo = F}
allspecies_log <- glm(occurrence ~ Value, data = train, family = "binomial")
mod_sum <- broom::tidy(allspecies_log)
mod_sum$p.value <- '< 0.001'
confint_res <- confint(allspecies_log)
rownames(confint_res) <- NULL
model_sum_tab <- cbind(mod_sum[,1], confint_res[,1], mod_sum[,2], confint_res[,2], mod_sum[,3:5])
colnames(model_sum_tab)[2] <- c('CI 2.5')
colnames(model_sum_tab)[4] <- c('CI 97.5')
knitr::kable(model_sum_tab)
```

We can present results using a classification table, more importantly this table will be  used to calculate a variety of metrics for evaluating the ability of the model to accurately classify observations. 
```{r Classification Table, echo = F}
pred_prob <- predict(allspecies_log, test, type = "response")
# Create a probabiliy table for the TRAINING Data
train$pred_class <- ifelse(allspecies_log$fitted.values >= 0.5, 1, 0)
ctab_train <- table(cut(train$Value, breaks = 2), cut(train$occurrence,
                                                      breaks = 2))
# now repeat the process for the TEST data
test$pred_class <- ifelse(pred_prob >= 0.5, 1, 0)
ctab_test <- table(cut(test$Value, breaks = 2), cut(test$occurrence, breaks = 2))
ctab_report <- cbind(as.data.frame.matrix(ctab_train), 
                     as.data.frame.matrix(ctab_test))
rownames(ctab_report) <- c('Absence','Presence')
colnames(ctab_report) <- c('Absence_train', 'Presence_train', 
                           'Absence_test', 'Presence_test')
knitr::kable(ctab_report)
rm(ctab_report)
```

```{r Model Diagnostics, echo = F}
accuracy_train <- sum(diag(ctab_train))/sum(ctab_train)*100
accuracy_test <- sum(diag(ctab_test))/sum(ctab_test)*100
# Calculate the True Positive Rate
Recall <- (ctab_train[2, 2]/sum(ctab_train[2, ]))*100
# Calculate the  True Negative Rate}
TNR <- (ctab_train[1, 1]/sum(ctab_train[1, ]))*100
# Calculate the Precision of the model 
Precision <- (ctab_train[2, 2]/sum(ctab_train[, 2]))*100
# Calculate F-score
F_Score <- (2 * Precision * Recall / (Precision + Recall))/100
# Reciever operator Curve
roc <- pROC::roc(train$occurrence, allspecies_log$fitted.values)
# Concordance}
concordance <- InformationValue::Concordance(allspecies_log$y,
                                             allspecies_log$fitted.values)
conc <- concordance[["Concordance"]]
disc <- concordance[["Discordance"]]
tied <- concordance[["Tied"]]
evaluation_table <- data.frame(
  'Metric' = c('Accuracy (Training)','Accuracy (Test)','Recall',
                          'True Neg. Rate','Precision', 'F-Score', 'AUC', 
                          'Concordance', 'Discordance', 'Tied'),
           'Value' = c(accuracy_train, accuracy_test, Recall, TNR, 
                       Precision, F_Score, as.numeric(roc[["auc"]]),
                       conc, disc, tied)
  )
evaluation_table$Value <- round(evaluation_table$Value, 2)
knitr::kable(evaluation_table)
rm(accuracy_train, accuracy_test, concordance, Recall, TNR, Precision, F_Score, roc,conc, disc, tied, pair, ctab_train, ctab_test, evaluation_table)
```

```{r create prediction plot, warning = F, echo = F}
newdata1 <- with(testing_data, data.frame(Value = mean(Value)))
newdata1$probability <- predict(allspecies_log, newdata = newdata1, type = "response")
newdata2 <- with(testing_data, 
                 data.frame(Value = rep(seq(from = 0.1, to = 1, length.out = 100), 4),
                                          Value = mean(Value)))
newdata3 <- cbind(newdata2, predict(allspecies_log, newdata = newdata2, type = "link",
    se = TRUE))
newdata3 <- within(newdata3, {
    PredictedProb <- plogis(fit)
    LL <- plogis(fit - (1.96 * se.fit))
    UL <- plogis(fit + (1.96 * se.fit))
})
testing_data$PredictedProb <- ifelse(testing_data$occurrence == 1, 1, 0)
ggplot(newdata3, aes(x = Value, y = PredictedProb)) + 
  geom_ribbon(aes(ymin = LL,ymax = UL), fill = 'red', alpha = 0.8) + 
  geom_line(size = 1) +
  geom_jitter(data = testing_data, aes(x = Value , y= PredictedProb), 
             alpha = 0.025, shape = 19, 
             height = 0.05, width = 0) +
  labs(title="Binomial Regression with Prediction Intervals and Data",
       x ="SDM Probability of Occurrence", y = "Occurrence") +
  theme(plot.title = element_text(hjust = 0.5)) +
  ylim(0,1) +
  theme_classic()
rm(newdata1, newdata2, newdata3)
```

