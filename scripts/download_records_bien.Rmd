---
title: "Download records from bien"
author: "steppe"
date: "3/31/2022"
output: pdf_document
---

```{r load libraries, results='hide', message=F, warning=F}
library(tidyverse) # data tidying
library(sf) # spatial data compliant with tidyverse
library(here)
library(BIEN)
set.seed(12)

source(here::here('scripts/sdm_functions.R'))
```

```{r import coords and prepare for upload to database}
poly_coords <- st_read(
  paste0(here(), '/data/processed/BIEN_polygons', '2022-03-31', '.shp'), 
  quiet = T) 

poly100 <- poly_coords[7,]
poly100_bb <- poly100 %>%  
  st_bbox()

rm(poly_coords)
```


# We will download all species occurrence records from within a 100 km radius of the study area. 

```{r download records from BIEN, eval = F}
poly_100_recs <- BIEN_occurrence_box(min.lat  = poly100_bb[2],
                                     max.lat  = poly100_bb[4],
                                     min.long = poly100_bb[1],
                                     max.long = poly100_bb[3]
                                     )

write.csv(poly_100_recs, paste0(here(), '/data/raw/100km_bien_occurrence.csv'))
rm(poly100_bb)
```


```{r Create grids which repeat regularly to extract land ownership too}
grids <- st_make_grid(st_transform(poly100, 32613), 
             cellsize = 5000,
             square = F, 
             flat_topped = T) %>% 
  st_intersection(., st_transform(poly100, 32613))

pad <- st_read(paste0(here(), 
         '/data/raw/PADUS2_1_Region7_Shapefile/PADUS2_1Fee_Region7.shp'),
  quiet = T) %>% 
  filter(State_Nm == 'CO') %>% 
  dplyr::select(Category, Mang_Name, d_Des_Tp)

grids <- st_transform(grids, st_crs(pad)) %>% 
  st_as_sf() %>% 
  mutate(ID = 1:nrow(.))

pad_grids <- st_intersection(pad, grids)

pad_grids1 <- st_as_sf(pad_grids) %>% 
 # group_by(Category, Mang_Name, d_Des_Tp, ID) %>% 
  #summarize(geometry = st_union(geometry)) %>% 
  mutate(PL_Area = as.numeric(st_area(.)))

grids <- grids %>% 
  mutate(GR_Area = as.numeric(st_area(.)))

public_lands_ownership <- left_join(grids,
                  st_drop_geometry(pad_grids1),
                  by = 'ID') %>% 
  group_by(ID, Category, Mang_Name, d_Des_Tp) %>% 
  mutate(PL_Area = replace_na(PL_Area, 0)) %>% 
  mutate(PL_Area = sum(PL_Area)) %>% 
  distinct(ID, .keep_all = T) %>% 
  ungroup() %>% 
  group_by(ID) %>% 
  mutate('PropPublicLand' = sum(PL_Area)/GR_Area) %>% 
  group_by(ID, Category, Mang_Name, d_Des_Tp) %>% 
  mutate('PropOfGrid' = PL_Area/GR_Area)

rm(pad_grids, pad_grids1, pad)
```


```{r load in and process tabular data}
poly_100_recs <- read.csv(paste0(here(), '/data/raw/100km_bien_occurrence.csv'))
poly_100_recs <- poly_100_recs %>%
  st_as_sf(coords = c(x = 'longitude', y = 'latitude'), crs = 4326) %>% 
  dplyr::select('scrubbed_species_binomial') 

poly100_t <- st_intersection(poly100, poly_100_recs)
poly100_t <- poly100_t[,3:4]

center <- st_centroid(poly100)
distances <- st_distance(center, poly100_t)
distances <- as.numeric(distances)
distances <- tibble(distances)

poly100_t_dist <- cbind(distances, poly100_t)
poly100_t_dist <- st_as_sf(poly100_t_dist) %>%
  distinct(scrubbed_species_binomial, distances, .keep_all = T)

poly100_unique <- poly100_t_dist %>% 
  group_by(scrubbed_species_binomial) %>%
  slice_min(n = 5, order_by = distances, with_ties = F) 

rm(center, poly_100_recs, distances, poly100_bb)
```


```{r Modelling Relationship between Proportion of Public Lands and Number of Records, warning = F}
poly100_t <- st_transform(poly100_t, st_crs(grids))
poly100_t <- poly100_t %>% 
  distinct(scrubbed_species_binomial, geometry, .keep_all = T)
rcs_pr_grid <- st_intersection(grids, poly100_t) %>% 
  count(ID) %>% 
  st_drop_geometry()

public_lands_ownership <- left_join(public_lands_ownership, rcs_pr_grid, by = 'ID') %>% 
  mutate(n = replace_na(n, 0))

ggplot() +
  geom_sf(data = poly100) +
  geom_sf(data = public_lands_ownership, aes(fill = n)) +
  theme_void()

rm(rcs_pr_grid)
```

# DETERMINE INFLATION OF RMBL RECORDS TO OTHER AREAS - DOWNSAMPLE. 

maybe just take the mean # of records from the adjacent cells? will then need to repeatedly subset the spp. richness from there...

The grid cell containing the RMBL records has a surplus of records relative to cells in other areas. It is challenging to model how many records may occur in this area without the Field Station Existence. Here we take an absurdly conservative approach to calculate the number of records which may exist in the area by taking the mean of the surrounding grid cells. The reason this approach will be conservative is that nearly all of the adjacent cells do **not** have road access to them, or they are in fact largely occupied by a ton and private property. 

```{r Identify Cells Adjacent to RMBL to determine how large of sample to take from RMBL Cell, warning = F}
grids_out <- poly100 %>% 
  st_centroid() %>%
  st_transform(32613) %>% 
  st_buffer(5000) %>% 
  st_transform(., st_crs(grids)) %>%
  st_intersection(. , grids)

poly100 <- st_transform(poly100, st_crs(grids_out))
grid2rm <- st_intersection(st_centroid(poly100), grids_out) %>% 
  dplyr::select(ID)

grids_out <- grids_out %>% 
  filter(ID != grid2rm$ID)

recs2sample <- filter(public_lands_ownership, ID %in% grids_out$ID) %>% 
  #dplyr::select(ID, n, PropPublicLand) %>% 
  st_drop_geometry() %>% 
  distinct(ID, .keep_all = T) %>% 
  ungroup() %>% 
  summarize(third_quart = round(quantile(n, prob = 0.75), 0))

```

90! Records to subset per iteration, I would estimate the real value to be around 200-250 given the ability to just drive up to the area. Anyways. We went with the third quantile rather than the mean value due to the adjacent cells being in road less wilderness areas, or for one having  a high proportion of private ownership. 

```{r prep data for going into sampler, warning = F}

poly100_t_dist <- poly100_t_dist %>% 
  mutate(Record_ID = 1:nrow(.))

target_grid <- filter(grids, ID == grid2rm$ID)

target_grid <- st_transform(target_grid, st_crs(poly100_t_dist))
focal_records <- st_intersection(target_grid, poly100_t_dist)

poly100_t_dist_sub <- poly100_t_dist %>% 
  filter(! Record_ID %in% focal_records$Record_ID) %>% 
  st_drop_geometry()
```


```{r subset the BIEN records and sample a proportion for logistic regression}

focal_records  <- focal_records %>% 
  dplyr::select(scrubbed_species_binomial, distances, Record_ID) %>% 
  st_drop_geometry()

abc <- spp_pres_sampler(target = focal_records, range = poly100_t_dist_sub, 
                        tSS = 87, rSS = 0.9, replicates = 250)

rm(focal_records, grid2rm, grids_out, poly100, public_lands_ownership, recs2sample, target_grid, poly100_t_dist_sub)
```


THESE RESULTS VERY CLOSE A COUPLE THINGS TO MAKE SURE TAXONOMY 1:1 MATCH UP - NOTE ORCHIDS ARE RESTRICTED FROM DB. 
```{r}
rmbl_plant_list <- read.csv(paste0(here(), '/data/processed/gothic_plant_list.csv'))[,c(1,4)]
rmbl_spp <- rmbl_plant_list$binomial
```

```{r, eval = F}
testing_data <- left_join(abc, poly100_t_dist, by = 'Record_ID') %>% 
  dplyr::select(-geometry) %>% 
  group_by(Iteration, scrubbed_species_binomial) %>% # the record further in space is
  slice_min(n = 1, order_by = distances) %>%  # pruned in this step 
  left_join(., rmbl_plant_list, by = c('scrubbed_species_binomial' ='binomial')) %>% 
  mutate(occurrence = if_else(!is.na(family), 1, 0) ) 

#all_spp <- poly100_unique %>%  
#  distinct(scrubbed_species_binomial, .keep_all = T)
```


```{r check for synonymy, message = F, results = 'hide', warning = F, eval=F}
library(WorldFlora)
#WFO.download()
WFO.remember()
     
rmbl_spp <- sort(rmbl_spp)
spec.test <- data.frame(spec.name=c(rmbl_spp))
target_results <- WFO.synonyms(spec.data=spec.test, WFO.data=WFO.data, counter=1, verbose=F)

spec.test1 <- poly100_unique %>% 
  distinct(scrubbed_species_binomial) %>% 
  pull()
museum_results <- WFO.synonyms(spec.data=spec.test1, WFO.data=WFO.data, counter=1, verbose=TRUE)

length(rmbl_spp) <- nrow(target_results)
length(spec.test1) <- nrow(museum_results)

rmbl_spp <- cbind('Species' = rmbl_spp, target_results)
target_spp <- cbind('Species' = spec.test1, museum_results)

write.csv(rmbl_spp, paste0(here(), '/data/processed/rmbl_spp_synonyms.csv'), row.names = F)
write.csv(target_spp, paste0(here(), '/data/processed/target_spp_synonyms.csv'), row.names = F)

rm(spec.test, spec.test1, museum_results, WFO.data)
```


```{r clean species lists, eval = F}

rmbl_spp <- read.csv(paste0(here(), '/data/processed/rmbl_spp_synonyms.csv'))
target_spp <- read.csv(paste0(here(), '/data/processed/target_spp_synonyms.csv'))

# i decided the results were good enough. this code still runs but put out what we basically put in.
rmbl_spp_CLEAN <- rmbl_spp %>% 
  filter(Species == scientificName)
rmbl_spp_DURTY <- rmbl_spp %>% 
  filter(Species != scientificName)

target_spp_CLEAN <- target_spp %>% 
  filter(Species == scientificName)
target_spp_DURTY <- target_spp %>% 
  filter(Species != scientificName)


# Here we will remove the species which were matched to genus but not to species
target_spp_CLEAN <- target_spp_DURTY %>% 
  mutate(scientificName = str_replace_all(scientificName, " ", "_")) %>% 
  filter(!str_detect(scientificName, '_')) %>% # WE WILL KEEP THE INPUT SPECIES HERE...
  mutate(scientificName = str_replace_all(scientificName, "_", " ")) %>% 
  mutate(scientificName = Species) %>% 
  bind_rows(., target_spp_CLEAN)
rmbl_spp_CLEAN <- rmbl_spp_DURTY %>% 
  mutate(scientificName = str_replace_all(scientificName, " ", "_")) %>% 
  filter(!str_detect(scientificName, '_')) %>% 
  mutate(scientificName = str_replace_all(scientificName, "_", " ")) %>% 
  mutate(scientificName = Species) %>% 
  bind_rows(., rmbl_spp_CLEAN)

# now perform the opposite
rmbl_spp_DURTY <- rmbl_spp_DURTY %>% 
  mutate(scientificName = str_replace_all(scientificName, " ", "_")) %>% 
  filter(str_detect(scientificName, '_')) %>% 
  mutate(scientificName = str_replace_all(scientificName, "_", " "))
target_spp_DURTY <- target_spp_DURTY %>% 
  mutate(scientificName = str_replace_all(scientificName, " ", "_")) %>% 
  filter(str_detect(scientificName, '_')) %>% 
  mutate(scientificName = str_replace_all(scientificName, "_", " "))

# THESE ARE EPITHETS WHICH ARE VALID FOR BOTH LISTS
rmbl_spp_CLEAN <- rmbl_spp_DURTY %>% 
  filter(scientificName %in% target_spp_CLEAN$scientificName)  %>% 
  bind_rows(., rmbl_spp_CLEAN)
target_spp_CLEAN <- target_spp_DURTY %>% 
  filter(scientificName %in% rmbl_spp_CLEAN$scientificName) %>% 
  bind_rows(., target_spp_CLEAN)

rmbl_spp_DURTY <- rmbl_spp_DURTY %>% 
  filter(!scientificName %in% target_spp_CLEAN$scientificName) 
target_spp_DURTY <- target_spp_DURTY %>% 
  filter(!scientificName %in% rmbl_spp_CLEAN$scientificName) 

# AT THIS POINT I FIND ACCEPTING THE REST OF KEWS NOTATIONS ACCEPTABLE . I DO NOT AGREE
# WITH ALL (NOTABLY THE STIPEAE TRIBE RETAINED IN THE GENUS STIPA S.L.), BUT WILL ACCEPT THEM...

rmbl_spp_clean <- bind_rows(rmbl_spp_CLEAN, rmbl_spp_DURTY)
target_spp_clean <- bind_rows(target_spp_CLEAN, target_spp_DURTY)

rm(rmbl_spp_CLEAN, rmbl_spp_DURTY, target_spp_CLEAN, target_spp_DURTY, target_spp_clean, rmbl_spp_clean)
```


```{r, message = F, results = 'hide', eval = F}
library(WorldFlora) # maybe you need this fam.
WFO.remember()

rmbl_spp <- filter(rmbl_spp, !is.na(Species))
rmbl_fam <- wfo_family_finder(rmbl_spp)
target_fam <- wfo_family_finder(target_spp)

# the same two records from both sets were not returned correctly
library(data.table)
setDT(rmbl_fam) # gotta use that slick that stuff. 
rmbl_fam[scientificName == 'Adoxa moschatellina',
         `:=`(Group = 'angiosperms', Family = "Adoxaceae", Order = 'Dipsacales', 
             Node.1 = 'Eudicots', Node.2 = 'Superasterids', Node.3 = 'Asterids',
             Node.4 = 'Campanulids')][scientificName == 'Sambucus racemosa',
                                      `:=`(Group = 'angiosperms', Family = "Adoxaceae", 
                                           Order = 'Dipsacales', Node.1 = 'Eudicots', Node.2 = 'Superasterids',
                                           Node.3 = 'Asterids', Node.4 = 'Campanulids')]
rmbl_fam <- tibble(rmbl_fam)
setDT(target_fam)
target_fam[scientificName == 'Adoxa moschatellina',
         `:=`(Group = 'angiosperms', Family = "Adoxaceae", Order = 'Dipsacales', 
             Node.1 = 'Eudicots', Node.2 = 'Superasterids', Node.3 = 'Asterids',
             Node.4 = 'Campanulids')][scientificName == 'Sambucus racemosa',
                                      `:=`(Group = 'angiosperms', Family = "Adoxaceae", 
                                           Order = 'Dipsacales', Node.1 = 'Eudicots', Node.2 = 'Superasterids',
                                           Node.3 = 'Asterids', Node.4 = 'Campanulids')]
target_fam <- tibble(target_fam)


write.csv(rmbl_fam, paste0(here(), '/data/processed/rmbl_spp_synonyms.csv'), row.names = F)
write.csv(target_fam, paste0(here(), '/data/processed/target_spp_synonyms.csv'), row.names = F)

rm(rmbl_fam, target_fam, WFO.data)
```

```{r}

# Draba oligosperma is in the REAL rmbl list
# Veronica americana is in the real rmbl list
# Androsace septentrionalis is in the real rmbl list
# Amelanchier pumila in RMBL needs recode to A. alnifolia
# Ivesia gordonii is IN REAL RMBL vascular plant list
# Hypericum maybe ambigious 
# Senecio crassulus is in real RMBL list
# Castilleja miniata is in the real RMBL list
# Minuartia obtusiloba should be in the RMBL digital list

rmbl_spp <- read.csv(paste0(here(), '/data/processed/rmbl_spp_synonyms.csv'))

rmbl_spp <- rmbl_spp %>% 
  mutate(scientificName = case_when(
    scientificName == 'Trollius' ~ 'Trollius albiflorus', 
    scientificName == 'Salix arctica' ~ 'Salix petrophila', 
    scientificName == 'Castilleja sulphurea' ~ 'Castilleja septentrionalis', 
    scientificName == 'Drymocallis arguta' ~ 'Potentilla arguta', 
    scientificName == 'Erysimum asperum' ~ 'Erysimum capitatum',  
    scientificName == 'Heracleum sphondylium' ~ 'Heracleum maximum',  
    scientificName == 'Potentilla anserina' ~ 'Argentea anserina',  
    scientificName == 'Sabulina rubella' ~ 'Minuartia rubella',
    TRUE ~ scientificName
  ))

target_spp <- read.csv(paste0(here(), '/data/processed/target_spp_synonyms.csv')) %>% 
  drop_na(Species)
```


```{r Append presence absence to each museum record species}

target_spp <- target_spp %>% 
  dplyr::select(Group:Node.1, Species, scientificName) %>% 
  mutate(occurrence = if_else(.$scientificName %in% rmbl_spp$scientificName, 1, 0)) %>% 
  na_if("") %>% 
  mutate(Node.1 = replace_na(Node.1, 'Vascular')) %>% 
  mutate('PrtyFlrs' = case_when(
    Group != 'angiosperms' ~ 0,
    Order != 'Poales' ~ 0,
    TRUE ~ 1
  ))

testing_data <- left_join(abc, poly100_t_dist, by = 'Record_ID') %>% 
  dplyr::select(-geometry) %>% 
  group_by(Iteration, scrubbed_species_binomial) %>% # the record further in space is
  slice_min(n = 1, order_by = distances) %>%  # pruned in this step 
  left_join(., target_spp, by = c('scrubbed_species_binomial' ='Species')) # %>% 
  mutate(occurrence = if_else(scrubbed_species_binomial %in% scientificName, 1, occurrence))

rm(target_spp, rmbl_spp)
```


## Assess Propotion of True Records

```{r}

dabs <- testing_data %>% 
  filter(occurrence == 0) %>% 
  arrange(distances) %>% 
  ungroup() %>% 
  distinct(scrubbed_species_binomial, .keep_all = T)

# I made it to 17km out
```


```{r, eval = F, warning = F}

td1 <- testing_data %>% 
  arrange(distances) %>% 
  ungroup() %>% 
  mutate(roll_sum = RcppRoll::roll_sum(occurrence, 500, align = "right", fill = NA)/500)

ggplot(td1, aes(x = distances, y = occurrence)) +
  geom_jitter(alpha = 0.01) 

td1$cuts <- cut(td1$distances, breaks = c(seq(0:50)*2000))


summary(binom_model <- glm(occurrence ~ distances, family = binomial, data = td1))
newdata <- data.frame(distances = seq(min(td1$distances), max(td1$distances),len=500))

#use fitted model to predict values of vs
newdata$occurrence = predict(binom_model, newdata, type="response")

#plot logistic regression curve
plot(occurrence ~ distances, data=td1, col="steelblue")
lines(occurrence ~ distances, newdata, lwd=2)



ggplot(td1, aes(x = distances, y = roll_sum)) +
  geom_density(stat = 'identity')

# Model 2 Using rollmeans as a predictor
summary(model <- glm(occurrence ~ distances + PrtyFlrs, family = poisson, data = td1))
pchisq(2 * (logLik(model) - logLik(model)), df = 1, lower.tail = FALSE)
(est <- cbind(Estimate = coef(model), confint(model)))

newdata1 <- data.frame(distances = mean(td1$distances),  PrtyFlrs = c(0,1))
newdata1$phat <- predict(model, newdata1, type = "response")

newdata2 <- data.frame(
  distances = rep(seq(from = min(td1$distances), to = max(td1$distances), length.out = 101), 3),
  PrtyFlrs = rep(0:1, length.out = 303)
)

newdata2 <- cbind(newdata2, predict(model, newdata2, type = "link", se.fit=TRUE))
newdata2 <- within(newdata2, {
  occurrences <- exp(fit)
  LL <- exp(fit - 1.96 * se.fit)
  UL <- exp(fit + 1.96 * se.fit)
})
newdata2$PrtyFlrs <- as.factor(newdata2$PrtyFlrs)
ggplot(newdata2, aes(distances, occurrences, groups = PrtyFlrs)) +
  geom_point(aes(colour = PrtyFlrs)) +
  geom_line(aes(group = PrtyFlrs, colour = PrtyFlrs))+
  labs(x = "Distance (m)", y = "Proportion of True Records")

simulationOutput <- DHARMa::simulateResiduals(model, plot = F, nBoot = 1000)
plot(simulationOutput)
DHARMa::testDispersion(simulationOutput)

```


## Logistic Regression Approach

split data set
```{r split data set, echo = F}
testing_data$distances <- testing_data$distances * -1
index <- caret::createDataPartition(testing_data$occurrence, p = .70, list = FALSE)
train <- testing_data[ index, ]
test  <- testing_data[-index, ]
rm(index)

```


```{r fit model, echo = F, message = F}
allspecies_log <- glm(occurrence ~ distances, data = train, family = "binomial")
mod_sum <- broom::tidy(allspecies_log)
mod_sum$p.value <- '< 0.001'
confint_res <- confint(allspecies_log)
rownames(confint_res) <- NULL
model_sum_tab <- cbind(mod_sum[,1], confint_res[,1], mod_sum[,2], confint_res[,2], mod_sum[,3:5])
colnames(model_sum_tab)[2] <- c('CI 2.5')
colnames(model_sum_tab)[4] <- c('CI 97.5')
knitr::kable(model_sum_tab)
```

We can present results using a classification table, more importantly this table will be  used to calculate a variety of metrics for evaluating the ability of the model to accurately classify observations. 
```{r Classification Table, echo = F}
pred_prob <- predict(allspecies_log, test, type = "response")
# Create a probability table for the TRAINING Data
train$pred_class <- ifelse(allspecies_log$fitted.values >= 0.5, 1, 0)
ctab_train <- table(cut(train$distances, breaks = 2), cut(train$occurrence,
                                                      breaks = 2))
# now repeat the process for the TEST data
test$pred_class <- ifelse(pred_prob >= 0.5, 1, 0)
ctab_test <- table(cut(test$distances, breaks = 2), cut(test$occurrence, breaks = 2))
ctab_report <- cbind(as.data.frame.matrix(ctab_train), 
                     as.data.frame.matrix(ctab_test))
rownames(ctab_report) <- c('Absence','Presence')
colnames(ctab_report) <- c('Absence_train', 'Presence_train', 
                           'Absence_test', 'Presence_test')
knitr::kable(ctab_report)
rm(ctab_report)
```

```{r Model Diagnostics, echo = F, warning = F}
accuracy_train <- sum(diag(ctab_train))/sum(ctab_train)*100
accuracy_test <- sum(diag(ctab_test))/sum(ctab_test)*100
# Calculate the True Positive Rate
Recall <- (ctab_train[2, 2]/sum(ctab_train[2, ]))*100
# Calculate the  True Negative Rate}
TNR <- (ctab_train[1, 1]/sum(ctab_train[1, ]))*100
# Calculate the Precision of the model 
Precision <- (ctab_train[2, 2]/sum(ctab_train[, 2]))*100
# Calculate F-score
F_Score <- (2 * Precision * Recall / (Precision + Recall))/100
# Reciever operator Curve
roc <- pROC::roc(train$occurrence, allspecies_log$fitted.values)
# Concordance}

evaluation_table <- data.frame(
  'Metric' = c('Accuracy (Training)','Accuracy (Test)','Recall',
                          'True Neg. Rate','Precision', 'F-Score', 'AUC'),
           'Value' = c(accuracy_train, accuracy_test, Recall, TNR, 
                       Precision, F_Score, as.numeric(roc[["auc"]]))
  )
evaluation_table$Value <- round(evaluation_table$Value, 2)
knitr::kable(evaluation_table)
rm(accuracy_train, accuracy_test, concordance, Recall, TNR, Precision, F_Score, roc, pair, ctab_train, ctab_test, evaluation_table)
```

```{r create prediction plot, warning = F, echo = F}
newdata1 <- with(testing_data, data.frame(distances = mean(distances)))
newdata1$probability <- predict(allspecies_log, newdata = newdata1, type = "response")
newdata2 <- with(testing_data, 
                 data.frame(distances = rep(seq(from = 0.1, to = 1, length.out = 10000), 4),
                                          distances = mean(distances)))
newdata3 <- cbind(newdata2, predict(allspecies_log, newdata = newdata2, type = "link",
    se = TRUE))
newdata3 <- within(newdata3, {
    PredictedProb <- plogis(fit)
    LL <- plogis(fit - (1.96 * se.fit))
    UL <- plogis(fit + (1.96 * se.fit))
})

testing_data$PredictedProb <- ifelse(testing_data$occurrence == 1, 1, 0)

ggplot(newdata3, aes(x = distances, y = PredictedProb)) + 
#  geom_ribbon(aes(ymin = LL, ymax = UL), fill = 'red', alpha = 0.8) + 
  geom_line() +
  geom_jitter(data = testing_data, aes(x = distances , y= PredictedProb), 
             alpha = 0.015, shape = 19, 
             height = 0.05, width = 0) +
  labs(title="Binomial Regression with Prediction Intervals and Data",
       x ="Distance (m)", y = "Occurrence") +
  theme(plot.title = element_text(hjust = 0.5)) +
  ylim(0,1) +
  theme_classic()

rm(newdata1, newdata2, newdata3)
```

