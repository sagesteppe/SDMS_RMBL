---
title: "Determine cutoff threadholds for classifying presences in ensembles"
author: "steppe"
date: "3/17/2022"
output: pdf_document
---



```{r load libraries, results='hide', message=F, warning=F}
library(tidyverse) # data tidying
library(sf) # spatial data compliant with tidyverse
library(raster) # raster data
library(here)
library(rgbif)

source(here::here('scripts/sdm_functions.R'))
set.seed(12)
```


```{r Create Raster Stack of Predictons}
predictions_stack <- paste0(here(), '/results/maps/',
list.files(paste0(here(), '/results/maps/'),
           pattern = "*.tif$" ))
predictions_stack <- raster::stack(predictions_stack)
```

We will use the ecoregion bound to query GBIF for more presence records for testing ensembles for prediction thresholds. We will also used the records which were removed from the intial BIEN data due to high levels of spatial auto-correlation. 
```{r Import Pruned Occurrence Records for Presences}
pseudo_abs <- st_read(paste0(here(), '/data/processed/Pseudo_absences_regression.shp'), 
                      quiet = T)[,c(1:4,21)]
recs_rm_spatial_auto <- pseudo_abs %>% filter(occurrence == 2)
true_recs <- pseudo_abs %>% filter(!is.na(PlotKey) | occurrence == 1 | occurrence == 2)
  
ecoregion_bound <- st_read(paste0(here(),'/data/processed/SoRo_ecoregion_bound.shp'), quiet = T)
```

We will also import the AIM dataset to feed in more true absences. 
```{r Import BLM data for more True Absence Records}
AIM <- st_read(paste0(here(),'/data/processed/AIM_Records_study_area.shp'), quiet = T) %>% 
  dplyr::select(-data)
```

We will scrape GBIF for some new records to test our preidcictions against. 
```{r check GBIF for new presence records, eval = F}
wkt_boundary <-  ecoregion_bound %>%  
  st_transform(4326) %>% 
  dplyr::select(ncol(.)) %>% 
  st_bbox()

species_vec <- true_recs %>% distinct(binomial) %>% pull(binomial) %>% 
  gsub("_", " ", .)

gbif_results_raw <-  lapply(species_vec, gbif_collector)
gbif_results_raw <- gbif_results_raw %>% 
  bind_rows() %>% 
  st_as_sf(coords = c(x = 'decimalLongitude', y = 'decimalLatitude'), 
           crs = 4326)

# st_write(gbif_results_raw, paste0(here(),'/data/raw/gbif_data.shp'))
rm(wkt_boundary, species_vec)
rm(list=lsf.str())
```

```{r determine which GBIF records are duplicates of BIEN records, eval = F}

gbif <- st_read(paste0(here(),'/data/raw/gbif_data.shp'), quiet = T)
gbif <- gbif %>% separate(scntfcN, c("genus", "epithet"), 
                          extra = "drop", remove = F) %>% 
  unite('binomial', genus:epithet, sep = "_") %>% 
  st_transform( 32613)
ecoregion_bound <- st_transform(ecoregion_bound, 32613)

gbif <- st_intersection(ecoregion_bound, gbif)

true_recs <- st_transform(true_recs, 32613) %>% st_buffer(400)

true_recs_list <- split(true_recs, ~binomial)
gbif_list <-split(gbif, ~binomial)

# ensure reciprocal matching between data sets
gbif_list_sub <- gbif_list[which(names(gbif_list) %in% names(true_recs_list))]
true_recs_list_sub <- true_recs_list[which(names(true_recs_list) %in% names(gbif_list_sub))]

# we can then calculate st-distance between the members of the two data sets. 
results <- mapply(st_intersects, gbif_list_sub, true_recs_list_sub)
results <- map(results, tibble) 
results <- data.table::rbindlist(results)
colnames(results) <- 'Intersects'

gbif <- bind_rows(gbif_list_sub) %>% 
  cbind(., results) %>% 
  mutate(Intersects = if_else(as.character(Intersects) == "integer(0)", F, T)) %>% 
  mutate(Intersects = as.logical(Intersects)) %>% 
  filter(Intersects == F)

st_write(gbif, paste0(here(),'/data/processed/gbif_data_clean.shp'), quiet = T)

rm(true_recs_list, gbif_list, results, gbif_list_sub, true_recs_list_sub, gbif)
```

```{r remove some datasets which are generated for the above chunk when eval is false on it, echo = F}
rm(true_recs)
```


```{r followup gbif cleaning to remove duplicates, eval = F}
gbif <- st_read( paste0(here(),'/data/processed/gbif_data_clean.shp'), quiet = T)

gbif <- gbif %>% filter(occrrnS == 'PRESENT') %>% 
  st_cast('POINT') %>% 
  filter(bssOfRc %in% c('PRESERVED_SPECIMEN','HUMAN_OBSERVATION','OCCURRENCE')) %>% 
  distinct(binomial, geometry, .keep_all = T)
  
st_write(gbif, paste0(here(),'/data/processed/gbif_data_clean.shp'), quiet = T, append = F)
```

```{r join new GBIF data with thinned data and draw new absences}
gbif <- st_read( paste0(here(),'/data/processed/gbif_data_clean.shp'), quiet = T) %>% 
  dplyr::select(binomial) %>% 
  mutate(PlotKey = "") %>% 
  st_transform(predictions_stack@crs@projargs)
gbif$PlotKey <- na_if(gbif$PlotKey, "")

presences <- recs_rm_spatial_auto %>% 
  dplyr::select(binomial, PlotKey) %>% 
  st_transform(predictions_stack@crs@projargs) %>% 
  rbind(., gbif)

rm(gbif, recs_rm_spatial_auto)
```

Process united data set to assess validity for binomial logistic regression
```{r clean dataset for logistic regression}
# we need at least 10 absence and presences to run a binomial logistic regression
presences <- presences %>% 
  add_count(binomial) %>% 
  filter(n >= 10) %>% 
  dplyr::select(-n)

# should i check for spatial autocorrelation here???? - technically yes but...
```

obtain BLM absences to generate our full test set for regression
```{r}
true_abs <- pseudo_abs %>%
  filter(!is.na(PlotKey) & occurrence == 0) 

presences_L <- st_transform(presences, 4269) %>%  
  mutate(occurrence = 1) %>% 
  split(., ~binomial)
true_abs_L <-  st_transform(true_abs, 4269) %>% 
  dplyr::select(binomial, PlotKey) %>% 
  mutate(occurrence = 0) %>% 
  split(., ~ binomial)
presences_L <- presences_L[which(names(presences_L) %in% names(true_abs_L))]
true_abs_L <- true_abs_L[which(names(true_abs_L) %in% names(presences_L))]

testing_set <- mapply(BinLogReg_abs, x = presences_L, y = true_abs_L,
                          SIMPLIFY = FALSE)
testing_set <- bind_rows(testing_set) 

testing_set %>% group_by(binomial) %>% 
  st_drop_geometry() %>% 
  count(occurrence) %>% 
  print()
rownames(testing_set) <- NULL

rm(true_abs, presences_L, true_abs_L, pseudo_abs)
```


```{r Extract SDM predictions to independent Presence/Absence Records, eval = F}

stacks <- names(predictions_stack) 
stacks <- gsub("_glm.*", "", stacks)
species <- testing_set %>% distinct(binomial) %>% pull()

# all species with a prediction and all species 
# with enough records to evaluate thresholds
positions <-intersect(stacks,species) 

# subset the evaluation data
testing_set <-testing_set %>% 
  filter(binomial %in% positions) %>% 
  st_transform(predictions_stack@crs@projargs)
testing_set_L <- split(testing_set, ~binomial) 
# to subset the raster stack to the species records
to_sub <- match(positions, stacks)
predictions_stack <- predictions_stack[[to_sub]]

# we now run a one to one extraction. 
values_data <-  vector(mode = "list", length = length(testing_set_L))
names(values_data) <- positions
for (i in 1:length(testing_set_L)){
  values_data[[i]] <- raster::extract(predictions_stack[[i]], testing_set_L[[i]],
                                      df = T)
}

# names(values_data) <- positions
values_data <- values_data %>% 
  map(~ rename(., Value = 2)) %>%
  bind_rows(., .id = "binomial")

testing_data <- testing_set %>% 
  st_drop_geometry( ) %>% 
  dplyr::select(occurrence) %>% 
  cbind(., values_data) %>%  
  dplyr::select(-ID)

write.csv(testing_data, paste0(here() , '/data/processed/logistic_regression_theshold_data.csv'), row.names = F)

rm(stacks, species, positions, to_sub, i, testing_set_L)
```


```{r clean up environment from processed data}
rm(AIM, ecoregion_bound, predictions_stack, presences, values_data, testing_set)
```

# Run models

```{r}
testing_data <- read.csv(paste0(here() , '/data/processed/logistic_regression_theshold_data.csv'))
```




